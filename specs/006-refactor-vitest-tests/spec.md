# Feature Specification: Refactor Vitest Tests to Resolve Failures

**Feature Branch**: `006-refactor-vitest-tests`  
**Created**: Thursday, September 11, 2025  
**Status**: Draft  
**Input**: User description: "Refactor Vitest tests to resolve widespread failures across src/ extension files and webview-react/ components, addressing environment setup, mocking, and assertion logic issues."

## Execution Flow (main)
```
1. Parse user description from Input
   ‚Üí If empty: ERROR "No feature description provided"
2. Extract key concepts from description
   ‚Üí Identify: actors, actions, data, constraints
3. For each unclear aspect:
   ‚Üí Mark with [NEEDS CLARIFICATION: specific question]
4. Fill User Scenarios & Testing section
   ‚Üí If no clear user flow: ERROR "Cannot determine user scenarios"
5. Generate Functional Requirements
   ‚Üí Each requirement must be testable
   ‚Üí Mark ambiguous requirements
6. Identify Key Entities (if data involved)
7. Run Review Checklist
   ‚Üí If any [NEEDS CLARIFICATION]: WARN "Spec has uncertainties"
   ‚Üí If implementation details found: ERROR "Remove tech details"
8. Return: SUCCESS (spec ready for planning)
```

---

## ‚ö° Quick Guidelines
- ‚úÖ Focus on WHAT users need and WHY
- ‚ùå Avoid HOW to implement (no tech stack, APIs, code structure)
- üë• Written for business stakeholders, not developers

### Section Requirements
- **Mandatory sections**: Must be completed for every feature
- **Optional sections**: Include only when relevant to the feature
- When a section doesn't apply, remove it entirely (don't leave as "N/A")

### For AI Generation
When creating this spec from a user prompt:
1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] for any assumption you'd need to make
2. **Don't guess**: If the prompt doesn't specify something (e.g., "login system" without auth method), mark it
3. **Think like a tester**: Every vague requirement should fail the "testable and unambiguous" checklist item
4. **Common underspecified areas**:
   - User types and permissions
   - Data retention/deletion policies  
   - Performance targets and scale
   - Error handling behaviors
   - Integration requirements
   - Security/compliance needs

---

## User Scenarios & Testing *(mandatory)*

### Primary User Story
As a developer, I want the Vitest test suite to accurately reflect the correctness of the codebase, with all tests passing, so that I can confidently develop and refactor features.

### Acceptance Scenarios
1. **Given** the project, **When** Vitest tests are executed, **Then** all tests pass, indicating a stable and correct codebase.
2. **Given** a `webview-react/` component test, **When** it is executed, **Then** it runs in a browser-like environment without `window is not defined` errors.
3. **Given** a `src/test/suite/` test, **When** it is executed, **Then** it correctly recognizes Vitest's global setup/teardown functions.
4. **Given** a test with mocking, **When** the test runs, **Then** mocks are correctly applied and assertions pass.

### Edge Cases
- What happens if a test relies on a specific VS Code API that cannot be easily mocked in Vitest?
- How should tests handle external dependencies (e.g., Qdrant service) that are not mocked?
- What if a test is inherently flaky and passes/fails inconsistently?

## Requirements *(mandatory)*

### Functional Requirements
- **FR-001**: Configure Vitest to correctly run tests for `webview-react/` components in a browser-like environment (e.g., using `jsdom` or `happy-dom`).
- **FR-002**: Ensure that `src/test/suite/` tests correctly utilize Vitest's global setup/teardown functions (`beforeEach`, `beforeAll`, etc.) instead of `setup` or `suiteSetup` if they are not globally available. This might involve updating test files to use Vitest's native APIs.
- **FR-003**: Investigate and correct mocking implementations in `src/tests/db/qdrantService.test.ts`, `src/tests/integration/configChange.test.ts`, `src/tests/contract/fileMonitorService.test.ts`, and `src/tests/contract/indexingService.test.ts` to ensure proper spy/mock behavior.
- **FR-004**: Review and correct assertion logic in `src/tests/integration/fileMonitoring.test.ts`, `src/test/suite/astParserErrorHandling.test.ts`, `src/test/suite/configurationService.test.ts`, `src/test/suite/startupFlow.integration.test.ts`, and `src/test/suite/startupService.test.ts` to match expected outcomes.
- **FR-005**: Address the `ENOENT` error in `src/test/suite/extensionLifecycle.test.ts` by adjusting the test to correctly reference `extension.ts` (source) instead of `extension.js` (compiled output), or by mocking the file system access if appropriate.
- **FR-006**: For tests with intentional `expect(true).toBe(false)` failures (e.g., in `specs/001-we-currently-have/tests/contracts/*.test.ts`), these should be updated to reflect the actual implementation and pass once the corresponding features are complete.

---

## Review & Acceptance Checklist
*GATE: Automated checks run during main() execution*

### Content Quality
- [ ] No implementation details (languages, frameworks, APIs)
- [ ] Focused on user value and business needs
- [ ] Written for non-technical stakeholders
- [ ] All mandatory sections completed

### Requirement Completeness
- [ ] No [NEEDS CLARIFICATION] markers remain
- [ ] Requirements are testable and unambiguous  
- [ ] Success criteria are measurable
- [ ] Scope is clearly bounded
- [ ] Dependencies and assumptions identified

---

## Execution Status
*Updated by main() during processing*

- [ ] User description parsed
- [ ] Key concepts extracted
- [ ] Ambiguities marked
- [ ] User scenarios defined
- [ ] Requirements generated
- [ ] Entities identified
- [ ] Review checklist passed

---